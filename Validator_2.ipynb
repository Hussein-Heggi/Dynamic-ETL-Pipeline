{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp, wasserstein_distance,energy_distance\n",
    "import pickle\n",
    "from scipy.spatial.distance import cdist, pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded successfully.\n",
      "‚Ü™Ô∏è Compatibility score: 0.78\n",
      "‚Ü™Ô∏è Columns in Dataset 1: 9\n",
      "‚Ü™Ô∏è Columns in Dataset 2: 9\n"
     ]
    }
   ],
   "source": [
    "with open('compatibility_analysis.pkl', 'rb') as f:\n",
    "    saved_data = pickle.load(f)\n",
    "\n",
    "# Unpack\n",
    "embeddings_1 = saved_data['embeddings_1']\n",
    "embeddings_2 = saved_data['embeddings_2']\n",
    "cols1_h = saved_data['cols1_h']\n",
    "cols2_h = saved_data['cols2_h']\n",
    "compatibility_score = saved_data['compatibility_score']\n",
    "\n",
    "print(\"‚úÖ Data loaded successfully.\")\n",
    "print(f\"‚Ü™Ô∏è Compatibility score: {compatibility_score:.2f}\")\n",
    "print(f\"‚Ü™Ô∏è Columns in Dataset 1: {len(cols1_h)}\")\n",
    "print(f\"‚Ü™Ô∏è Columns in Dataset 2: {len(cols2_h)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Match Found: open ‚ÜîÔ∏è open (similarity: 1.00)\n",
      "üîó Match Found: high ‚ÜîÔ∏è high (similarity: 1.00)\n",
      "üîó Match Found: low ‚ÜîÔ∏è low (similarity: 1.00)\n",
      "üîó Match Found: close ‚ÜîÔ∏è close (similarity: 1.00)\n",
      "üîó Match Found: volume ‚ÜîÔ∏è volume (similarity: 1.00)\n",
      "üîó Match Found: vwap ‚ÜîÔ∏è vwap (similarity: 1.00)\n",
      "üîó Match Found: timestamp ‚ÜîÔ∏è timestamp (similarity: 1.00)\n",
      "üîó Match Found: transactions ‚ÜîÔ∏è transactions (similarity: 1.00)\n",
      "üîó Match Found: otc ‚ÜîÔ∏è otc (similarity: 1.00)\n",
      "\n",
      "üîç Closest Column Matches (threshold ‚â• 0.85):\n",
      "- open ‚Üí open (similarity: 1.00)\n",
      "- high ‚Üí high (similarity: 1.00)\n",
      "- low ‚Üí low (similarity: 1.00)\n",
      "- close ‚Üí close (similarity: 1.00)\n",
      "- volume ‚Üí volume (similarity: 1.00)\n",
      "- vwap ‚Üí vwap (similarity: 1.00)\n",
      "- timestamp ‚Üí timestamp (similarity: 1.00)\n",
      "- transactions ‚Üí transactions (similarity: 1.00)\n",
      "- otc ‚Üí otc (similarity: 1.00)\n"
     ]
    }
   ],
   "source": [
    "# Compute cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(embeddings_1, embeddings_2)\n",
    "\n",
    "# Set similarity threshold\n",
    "SIMILARITY_THRESHOLD = 0.85\n",
    "Matching_THRESHOLD = 0.95\n",
    "match_count = 0\n",
    "\n",
    "# Map only columns above the threshold\n",
    "closest_matches = {}\n",
    "for i, row in enumerate(similarity_matrix):\n",
    "    j_best = np.argmax(row)\n",
    "    best_score = row[j_best]\n",
    "    if best_score >= SIMILARITY_THRESHOLD:\n",
    "        col_1 = cols1_h[i]\n",
    "        col_2 = cols2_h[j_best]\n",
    "        closest_matches[col_1] = (col_2, best_score)\n",
    "    if best_score >= Matching_THRESHOLD:\n",
    "        match_count += 1\n",
    "        print(f\"üîó Match Found: {cols1_h[i]} ‚ÜîÔ∏è {cols2_h[j_best]} (similarity: {best_score:.2f})\")\n",
    "\n",
    "Match_score = match_count/len(closest_matches)\n",
    "\n",
    "# Report matches\n",
    "print(f\"\\nüîç Closest Column Matches (threshold ‚â• {SIMILARITY_THRESHOLD}):\")\n",
    "if closest_matches:\n",
    "    for col1, (col2, score) in closest_matches.items():\n",
    "        print(f\"- {col1} ‚Üí {col2} (similarity: {score:.2f})\")\n",
    "else:\n",
    "    print(\"No matches above threshold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing File 1\n",
      "Original dtypes:\n",
      "open            float64\n",
      "high            float64\n",
      "low             float64\n",
      "close           float64\n",
      "volume          float64\n",
      "vwap            float64\n",
      "timestamp         int64\n",
      "transactions      int64\n",
      "otc             float64\n",
      "dtype: object\n",
      "\n",
      "No columns were converted.\n",
      "\n",
      "Processing File 2\n",
      "Original dtypes:\n",
      "open            float64\n",
      "high            float64\n",
      "low             float64\n",
      "close           float64\n",
      "volume          float64\n",
      "vwap            float64\n",
      "timestamp         int64\n",
      "transactions      int64\n",
      "otc             float64\n",
      "dtype: object\n",
      "\n",
      "No columns were converted.\n"
     ]
    }
   ],
   "source": [
    "def convert_columns_to_numeric(df, file_label=\"\"):\n",
    "    print(f\"\\nProcessing {file_label}\")\n",
    "    print(\"Original dtypes:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    converted_cols = {}\n",
    "    for col in df.columns:\n",
    "        original_dtype = df[col].dtype\n",
    "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            new_dtype = df[col].dtype\n",
    "            if new_dtype != original_dtype:\n",
    "                converted_cols[col] = (original_dtype, new_dtype)\n",
    "\n",
    "    if converted_cols:\n",
    "        print(\"\\nColumns converted:\")\n",
    "        for col, (orig, new) in converted_cols.items():\n",
    "            print(f\" - {col}: {orig} -> {new}\")\n",
    "    else:\n",
    "        print(\"\\nNo columns were converted.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Replace these with your actual CSV file paths\n",
    "file1_path = '/home/g7/Desktop/Thesis I/Datasets/Ingestor_Datasets/DF_1.csv'\n",
    "file2_path = '/home/g7/Desktop/Thesis I/Datasets/Ingestor_Datasets/DF_2.csv'\n",
    "\n",
    "df1 = pd.read_csv(file1_path)\n",
    "df2 = pd.read_csv(file2_path)\n",
    "\n",
    "df1 = convert_columns_to_numeric(df1, \"File 1\")\n",
    "df2 = convert_columns_to_numeric(df2, \"File 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ks_tests(df1, df2, column_mapping):\n",
    "    ks_stats = []\n",
    "    p_values = []\n",
    "\n",
    "    for col1, (col2, _) in column_mapping.items():\n",
    "        if col1 not in df1.columns or col2 not in df2.columns:\n",
    "            continue\n",
    "\n",
    "        if not pd.api.types.is_numeric_dtype(df1[col1]) or not pd.api.types.is_numeric_dtype(df2[col2]):\n",
    "            continue\n",
    "\n",
    "        series1 = df1[col1].dropna()\n",
    "        series2 = df2[col2].dropna()\n",
    "\n",
    "        if len(series1) == 0 or len(series2) == 0:\n",
    "            continue\n",
    "\n",
    "        stat, p_value = ks_2samp(series1, series2)\n",
    "\n",
    "        ks_stats.append(stat)\n",
    "        p_values.append(p_value)\n",
    "\n",
    "    avg_ks = sum(ks_stats) / len(ks_stats) if ks_stats else None\n",
    "    avg_p = sum(p_values) / len(p_values) if p_values else None\n",
    "\n",
    "    return avg_ks, avg_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Avg KS Statistic: 0.7248\n",
      "üìä Avg p-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "avg_ks, avg_p = run_ks_tests(df1, df2, closest_matches)\n",
    "print(f\"üìä Avg KS Statistic: {avg_ks:.4f}\")\n",
    "print(f\"üìä Avg p-value: {avg_p:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wasserstein_test(df1, df2, column_mapping):\n",
    "    distances = []\n",
    "\n",
    "    for col1, (col2, _) in column_mapping.items():\n",
    "        if col1 not in df1.columns or col2 not in df2.columns:\n",
    "            continue\n",
    "\n",
    "        if not pd.api.types.is_numeric_dtype(df1[col1]) or not pd.api.types.is_numeric_dtype(df2[col2]):\n",
    "            continue\n",
    "\n",
    "        series1 = df1[col1].dropna()\n",
    "        series2 = df2[col2].dropna()\n",
    "\n",
    "        if len(series1) == 0 or len(series2) == 0:\n",
    "            continue\n",
    "\n",
    "        # Normalize both series with z-score\n",
    "        s1 = (series1 - series1.mean()) / series1.std()\n",
    "        s2 = (series2 - series2.mean()) / series2.std()\n",
    "\n",
    "        dist = wasserstein_distance(s1, s2)\n",
    "        distances.append(dist)\n",
    "\n",
    "    avg_dist = sum(distances) / len(distances) if distances else None\n",
    "    return avg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìè Average Wasserstein Distance: 0.3260\n"
     ]
    }
   ],
   "source": [
    "avg_wasserstein = run_wasserstein_test(df1, df2, closest_matches)\n",
    "print(f\"üìè Average Wasserstein Distance: {avg_wasserstein:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psi(expected, actual, bins=2):\n",
    "    expected = expected.dropna()\n",
    "    actual = actual.dropna()\n",
    "\n",
    "    if isinstance(bins, int):\n",
    "        bin_edges = np.percentile(expected, np.linspace(0, 100, bins + 1))\n",
    "        bin_edges = np.unique(bin_edges)  # Remove duplicates\n",
    "        if len(bin_edges) < 2:\n",
    "            return np.nan  # Cannot bin a constant column\n",
    "    else:\n",
    "        bin_edges = bins\n",
    "\n",
    "    expected_bins = np.histogram(expected, bins=bin_edges)[0]\n",
    "    actual_bins = np.histogram(actual, bins=bin_edges)[0]\n",
    "\n",
    "    if expected_bins.sum() == 0 or actual_bins.sum() == 0:\n",
    "        return np.nan  # Avoid divide by zero\n",
    "\n",
    "    expected_dist = expected_bins / expected_bins.sum()\n",
    "    actual_dist = actual_bins / actual_bins.sum()\n",
    "\n",
    "    # Add small value to avoid log(0) or divide-by-zero\n",
    "    epsilon = 1e-6\n",
    "    psi = np.sum((expected_dist - actual_dist) * np.log((expected_dist + epsilon) / (actual_dist + epsilon)))\n",
    "\n",
    "    return psi\n",
    "\n",
    "def run_psi_tests(df1, df2, column_mapping, bins=4, epsilon=1e-4):\n",
    "    psi_values = []\n",
    "\n",
    "    for col1, (col2, _) in column_mapping.items():\n",
    "        if col1 not in df1.columns or col2 not in df2.columns:\n",
    "            continue\n",
    "\n",
    "        if not pd.api.types.is_numeric_dtype(df1[col1]) or not pd.api.types.is_numeric_dtype(df2[col2]):\n",
    "            continue\n",
    "\n",
    "        series1 = df1[col1].dropna()\n",
    "        series2 = df2[col2].dropna()\n",
    "\n",
    "        if len(series1) == 0 or len(series2) == 0:\n",
    "            continue\n",
    "\n",
    "        psi = calculate_psi(series1, series2, bins=bins)\n",
    "        psi_values.append(psi if not np.isnan(psi) else epsilon)\n",
    "\n",
    "    avg_psi = sum(psi_values) / len(psi_values) if psi_values else None\n",
    "    return avg_psi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Average PSI (with fallback for NaNs): 0.3414\n"
     ]
    }
   ],
   "source": [
    "avg_psi = run_psi_tests(df1, df2, closest_matches, bins=4)\n",
    "print(f\"üìä Average PSI (with fallback for NaNs): {avg_psi:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_energy_distance(df1, df2, column_mapping):\n",
    "    cols1 = []\n",
    "    cols2 = []\n",
    "\n",
    "    for col1, (col2, _) in column_mapping.items():\n",
    "        if col1 not in df1.columns or col2 not in df2.columns:\n",
    "            continue\n",
    "        if not pd.api.types.is_numeric_dtype(df1[col1]) or not pd.api.types.is_numeric_dtype(df2[col2]):\n",
    "            continue\n",
    "\n",
    "        s1 = df1[col1].dropna()\n",
    "        s2 = df2[col2].dropna()\n",
    "\n",
    "        min_len = min(len(s1), len(s2))\n",
    "        if min_len == 0:\n",
    "            continue\n",
    "\n",
    "        # Z-score normalize both series\n",
    "        s1 = (s1 - s1.mean()) / s1.std()\n",
    "        s2 = (s2 - s2.mean()) / s2.std()\n",
    "\n",
    "        cols1.append(s1.iloc[:min_len].to_numpy())\n",
    "        cols2.append(s2.iloc[:min_len].to_numpy())\n",
    "\n",
    "    if not cols1 or not cols2:\n",
    "        return None\n",
    "\n",
    "    X = np.array(cols1).T  # shape: (n_samples, n_features)\n",
    "    Y = np.array(cols2).T\n",
    "\n",
    "    # Compute energy distance\n",
    "    d_xy = cdist(X, Y).mean()\n",
    "    d_xx = pdist(X).mean() if len(X) > 1 else 0\n",
    "    d_yy = pdist(Y).mean() if len(Y) > 1 else 0\n",
    "\n",
    "    energy_dist = 2 * d_xy - d_xx - d_yy\n",
    "    return energy_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Energy Distance (multivariate): 0.1861\n"
     ]
    }
   ],
   "source": [
    "energy_dist = run_energy_distance(df1, df2, closest_matches)\n",
    "print(f\"‚ö° Energy Distance (multivariate): {energy_dist:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_scores(ks_stat, p_value, wasserstein, psi, energy, compatibility_score, match_score, weights=None):\n",
    "    \n",
    "    if weights is None:\n",
    "        weights = {\n",
    "            'ks': 1.0,\n",
    "            'p': 1.0,\n",
    "            'wasserstein': 1.0,\n",
    "            'psi': 1.0,\n",
    "            'energy': 1.0,\n",
    "            'compatibility_score': 1.5,\n",
    "            'match_score': 4.0\n",
    "        }\n",
    "\n",
    "    scores = {\n",
    "        'ks': ks_stat,\n",
    "        'p': 1 - p_value,\n",
    "        'wasserstein': min(wasserstein / 1.0, 1.0),\n",
    "        'psi': min(psi / 0.25, 1.0),\n",
    "        'energy': min(energy / 1.0, 1.0),\n",
    "        'compatibility_score': compatibility_score,\n",
    "        'match_score': match_score\n",
    "    }\n",
    "\n",
    "    weighted_sum = sum(scores[k] * weights[k] for k in scores)\n",
    "    total_weight = sum(weights.values())\n",
    "    final_score = weighted_sum / total_weight\n",
    "\n",
    "    print(f\"\\nüîç Final Score: {final_score:.4f}\")\n",
    "\n",
    "    if final_score >= 0.80:\n",
    "        return \"Compatible\"\n",
    "    elif final_score >= 0.60:\n",
    "        return \"Borderline\"\n",
    "    else:\n",
    "        return \"Incompatible\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Final Score: 0.8004\n",
      "\n",
      "üîç Final Decision: Compatible\n"
     ]
    }
   ],
   "source": [
    "Decision = combine_scores(ks_stat=avg_ks, p_value=avg_p, wasserstein=avg_wasserstein, psi=avg_psi, energy=energy_dist, compatibility_score=compatibility_score, match_score=Match_score)\n",
    "print(f\"\\nüîç Final Decision: {Decision}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
